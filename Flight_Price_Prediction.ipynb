{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8c5621",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Flight Price Category Prediction\\n\",\n",
    "    \"\\n\",\n",
    "    \"This Jupyter Notebook contains the code for the Flight Price Category Prediction project. The goal is to build a machine learning model that can classify flights as either 'Cheap' or 'Expensive' based on various features. \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Import necessary libraries\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"from sklearn.ensemble import RandomForestClassifier\\n\",\n",
    "    \"from sklearn.metrics import confusion_matrix, classification_report\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Step 1: Data Loading and Preprocessing\\n\",\n",
    "    \"\\n\",\n",
    "    \"First, we'll load the dataset and perform some initial cleaning and preprocessing steps. This includes cleaning column names and transforming the continuous 'price' variable into a categorical 'Price_Category' suitable for a classification task.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Load the dataset\\n\",\n",
    "    \"df = pd.read_csv(\\\"data/FlightBooking.csv\\\")\\n\",\n",
    "    \"df.columns = df.columns.str.strip() # Clean column names\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Drop unwanted index column if present\\n\",\n",
    "    \"if 'Unnamed: 0' in df.columns:\\n\",\n",
    "    \"    df.drop(columns=['Unnamed: 0'], inplace=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Convert continuous price values into categories: Cheap and Expensive\\n\",\n",
    "    \"df['Price_Category'] = pd.cut(df['price'],\\n\",\n",
    "    \"                                 bins=[0, 10000, float('inf')],\\n\",\n",
    "    \"                                 labels=['Cheap', 'Expensive'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"First 5 rows of the dataset:\\\")\\n\",\n",
    "    \"print(df.head())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Step 2: Feature Engineering and Data Splitting\\n\",\n",
    "    \"\\n\",\n",
    "    \"We'll separate the features (`X`) from the target variable (`y`). Categorical features are converted into a numerical format using one-hot encoding, and the data is then split into training and testing sets to evaluate the model's performance on unseen data.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Prepare features and target\\n\",\n",
    "    \"X = df.drop(columns=['price', 'Price_Category'])\\n\",\n",
    "    \"X = pd.get_dummies(X, drop_first=True) # Encode categorical variables\\n\",\n",
    "    \"y = df['Price_Category']\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Split data into training and test sets\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Training set shape: {X_train.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Testing set shape: {X_test.shape}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Step 3: Model Training and Prediction\\n\",\n",
    "    \"\\n\",\n",
    "    \"A Random Forest Classifier, known for its strong performance in classification tasks, is trained on the training data. The model then makes predictions on the unseen test data.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Train the Random Forest Classifier\\n\",\n",
    "    \"model = RandomForestClassifier()\\n\",\n",
    "    \"model.fit(X_train, y_train)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Predict on the test set\\n\",\n",
    "    \"y_pred = model.predict(X_test)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Step 4: Model Evaluation and Visualization\\n\",\n",
    "    \"\\n\",\n",
    "    \"To evaluate the model's performance, we'll generate a confusion matrix and a classification report. Visualizations are created to better understand the results.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Generate and plot confusion matrix\\n\",\n",
    "    \"cm = confusion_matrix(y_test, y_pred)\\n\",\n",
    "    \"plt.figure(figsize=(6, 4))\\n\",\n",
    "    \"sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \\n\",\n",
    "    \"            xticklabels=['Cheap', 'Expensive'],\\n\",\n",
    "    \"            yticklabels=['Cheap', 'Expensive'])\\n\",\n",
    "    \"plt.title(\\\"Confusion Matrix\\\")\\n\",\n",
    "    \"plt.xlabel(\\\"Predicted\\\")\\n\",\n",
    "    \"plt.ylabel(\\\"Actual\\\")\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Print classification report\\n\",\n",
    "    \"print(\\\"Classification Report:\\\")\\n\",\n",
    "    \"print(classification_report(y_test, y_pred))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot actual vs predicted output for a sample\\n\",\n",
    "    \"num_samples = 30\\n\",\n",
    "    \"y_test_sample = y_test.iloc[:num_samples].reset_index(drop=True)\\n\",\n",
    "    \"y_pred_sample = pd.Series(y_pred[:num_samples])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot actual vs predicted values\\n\",\n",
    "    \"plt.figure(figsize=(14, 6))\\n\",\n",
    "    \"x = np.arange(num_samples)\\n\",\n",
    "    \"plt.plot(x, y_test_sample, marker='o', label='Actual', color='green')\\n\",\n",
    "    \"plt.plot(x, y_pred_sample, marker='x', label='Predicted', color='red')\\n\",\n",
    "    \"plt.title('Actual vs Predicted Price Category (Sample of 30)')\\n\",\n",
    "    \"plt.xlabel('Sample Index')\\n\",\n",
    "    \"plt.ylabel('Price Category')\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"plt.grid(True)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.5\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
